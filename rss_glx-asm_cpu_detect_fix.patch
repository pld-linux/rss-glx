diff -aurN rss_glx-0.7.4.orig/reallyslick/c_src/rsMath.c rss_glx-0.7.4/reallyslick/c_src/rsMath.c
--- rss_glx-0.7.4.orig/reallyslick/c_src/rsMath.c	2003-03-02 00:56:28.000000000 +0100
+++ rss_glx-0.7.4/reallyslick/c_src/rsMath.c	2003-06-21 20:39:49.000000000 +0200
@@ -37,36 +37,34 @@
 void rsCPUDetect() {
 #ifdef DETECT_X86_EXTS
 	__asm__ (
-	"
-		xor	%%eax, %%eax
+		"xor	%%eax, %%eax\n\t"
 
-		cpuid
+		"cpuid\n\t"
 
-		cmp	$0x68747541, %%ebx
-		jne	not_amd
+		"cmp	$0x68747541, %%ebx\n\t"
+		"jne	not_amd\n\t"
 
-		mov	$0x80000001, %%eax
-		cpuid
+		"mov	$0x80000001, %%eax\n\t"
+		"cpuid\n\t"
 
-		shr	$31, %%edx
-		jmp	done
+		"shr	$31, %%edx\n\t"
+		"jmp	done\n\t"
 
-not_amd:
-		xor	%%edx, %%edx
-		cmp	$1, %%eax
-		jl	no_exts
+"not_amd:\n\t"
+		"xor	%%edx, %%edx\n\t"
+		"cmp	$1, %%eax\n\t"
+		"jl	no_exts\n\t"
 
-		xor	%%eax, %%eax
-		inc	%%eax
+		"xor	%%eax, %%eax\n\t"
+		"inc	%%eax\n\t"
 
-		cpuid
+		"cpuid\n\t"
 
-		shr	$24, %%edx
-		and	$2, %%edx
+		"shr	$24, %%edx\n\t"
+		"and	$2, %%edx\n\t"
 
-no_exts:
-done:
-	"
+"no_exts:\n\t"
+"done:\n\t"	
 	: "=d" (cpuid)
 	:
 	: "%eax", "%ebx", "%ecx"
@@ -86,48 +84,47 @@
 #ifdef USE_3DNOW
 	if (cpuid & FLAG_3DNOW) {
 		__asm__ (
-		"
-		femms
+		
+		"femms\n\t"
 
-		movq            (%1), %%mm0             /* 1 | 0 */
-		movq            8(%1), %%mm1            /* - | 2 */
+		"movq            (%1), %%mm0\n\t"
+		"movq            8(%1), %%mm1\n\t"
 
-		movq            %%mm0, %%mm2            /* 1 | 0 */
-		movq            %%mm1, %%mm3            /* - | 2 */
+		"movq            %%mm0, %%mm2\n\t"
+		"movq            %%mm1, %%mm3\n\t"
 
-		pfmul           %%mm0, %%mm0            /* 1 * 1 | 0 * 0 */
-		pfmul           %%mm1, %%mm1            /* -     | 2 * 2 */
+		"pfmul           %%mm0, %%mm0\n\t"
+		"pfmul           %%mm1, %%mm1\n\t"
 
-		movq            %%mm0, %%mm7            /* 1 * 1 | 0 * 0 */
-		punpckhdq       %%mm7, %%mm7            /* 1 * 1 | 1 * 1 */
+		"movq            %%mm0, %%mm7\n\t"
+		"punpckhdq       %%mm7, %%mm7\n\t"
 
-		pfadd           %%mm1, %%mm0            /* -     | 0 * 0 + 2 * 2 */
-		pfadd           %%mm7, %%mm0            /* -     | 0 * 0 + 2 * 2 + 1 * 1 */
+		"pfadd           %%mm1, %%mm0\n\t"
+		"pfadd           %%mm7, %%mm0\n\t"
 
-		pfrsqrt         %%mm0, %%mm1            /* 24-bit sqrt */
-		movq            %%mm1, %%mm4
-		pfmul           %%mm1, %%mm1
-		punpckldq       %%mm0, %%mm0
-		pfrsqit1        %%mm0, %%mm1
-		pfrcpit2        %%mm4, %%mm1
-		pfmul           %%mm1, %%mm0
+		"pfrsqrt         %%mm0, %%mm1\n\t"
+		"movq            %%mm1, %%mm4\n\t"
+		"pfmul           %%mm1, %%mm1\n\t"
+		"punpckldq       %%mm0, %%mm0\n\t"
+		"pfrsqit1        %%mm0, %%mm1\n\t"
+		"pfrcpit2        %%mm4, %%mm1\n\t"
+		"pfmul           %%mm1, %%mm0\n\t"
 
-		movd            %%mm0, %0               /* length */
+		"movd            %%mm0, %0\n\t"
 
-		pfrcp           %%mm0, %%mm1            /* 24-bit reciprocal */
-		movq            %%mm0, %%mm4
-		punpckldq       %%mm4, %%mm4
-		pfrcpit1        %%mm1, %%mm4
-		pfrcpit2        %%mm1, %%mm4
+		"pfrcp           %%mm0, %%mm1\n\t"
+		"movq            %%mm0, %%mm4\n\t"
+		"punpckldq       %%mm4, %%mm4\n\t"
+		"pfrcpit1        %%mm1, %%mm4\n\t"
+		"pfrcpit2        %%mm1, %%mm4\n\t"
 
-		pfmul           %%mm4, %%mm2            /* 1 / length | 0 / length */
-		pfmul           %%mm4, %%mm3            /* -          | 2 / length */
+		"pfmul           %%mm4, %%mm2\n\t"
+		"pfmul           %%mm4, %%mm3\n\t"
 
-		movq            %%mm2, (%1)             /* 1 | 0 */
-		movq            %%mm3, 8(%1)            /* - | 2 */
+		"movq            %%mm2, (%1)\n\t"
+		"movq            %%mm3, 8(%1)\n\t"
 
-		femms
-		"
+		"femms\n\t"
 		: "=m" (length)
 		: "d" (v)
 		);
@@ -139,27 +136,26 @@
 #ifdef USE_SSE
 	if (cpuid & FLAG_SSE) {
 		__asm__ (
-		"
-		movups          (%1), %%xmm0            /* 0 | 1 | 2 | - */
-		movups          %%xmm0, %%xmm1          /* 0 | 1 | 2 | - */
-
-		mulps           %%xmm0, %%xmm0          /* 0 * 0 | 1 * 1 | 2 * 2 | - */
-		movups          %%xmm0, %%xmm2          /* 0 * 0 | 1 * 1 | 2 * 2 | - */
-
-		shufps          $9, %%xmm2, %%xmm2      /* 1 * 1                 | 2 * 2 | - | - */
-		addss           %%xmm2, %%xmm0          /* 0 * 0 + 1 * 1         | -     | - | - */
-		shufps          $1, %%xmm2, %%xmm2      /* 2 * 2                 | -     | - | - */
-		addss           %%xmm2, %%xmm0          /* 0 * 0 + 1 * 1 + 2 * 2 | -     | - | - */
-
-		sqrtss          %%xmm0, %%xmm0          /* length | -      | -      | - */
-		movss           %%xmm0, %0              /* length */
-
-		unpcklps        %%xmm0, %%xmm0          /* length | length | -      | - */
-		unpcklps        %%xmm0, %%xmm0          /* length | length | length | length */
-		divps           %%xmm0, %%xmm1          /* 1 / length | 2 / length | 3 / length | - */
+		
+		"movups          (%1), %%xmm0\n\t"
+		"movups          %%xmm0, %%xmm1\n\t"
+
+		"mulps           %%xmm0, %%xmm0\n\t"
+		"movups          %%xmm0, %%xmm2\n\t"
+
+		"shufps          $9, %%xmm2, %%xmm2\n\t"
+		"addss           %%xmm2, %%xmm0\n\t"
+		"shufps          $1, %%xmm2, %%xmm2\n\t"
+		"addss           %%xmm2, %%xmm0\n\t"
+
+		"sqrtss          %%xmm0, %%xmm0\n\t"
+		"movss           %%xmm0, %0\n\t"
+
+		"unpcklps        %%xmm0, %%xmm0\n\t"
+		"unpcklps        %%xmm0, %%xmm0\n\t"
+		"divps           %%xmm0, %%xmm1\n\t"
 
-		movups          %%xmm1, (%1)            /* 1 / length | 2 / length | 3 / length | - */
-		"
+		"movups          %%xmm1, (%1)\n\t"
 		: "=m" (length)
 		: "d" (v)
 		);
@@ -187,41 +183,40 @@
 #ifdef USE_3DNOW
 	if (cpuid & FLAG_3DNOW) {
 		__asm__ (
-		"
-		femms
+		
+		"femms\n\t"
 
-		movq            (%0), %%mm0             /* 1.1 | 1.0 */
-		movq            8(%0), %%mm1            /* -   | 1.2 */
+		"movq            (%0), %%mm0\n\t"
+		"movq            8(%0), %%mm1\n\t"
 
-		movq            (%1), %%mm2             /* 2.1 | 2.0 */
-		movq            8(%1), %%mm3            /* -   | 2.2 */
+		"movq            (%1), %%mm2\n\t"
+		"movq            8(%1), %%mm3\n\t"
 
-		movq            %%mm0, %%mm4            /* 1.1 | 1.0 */
-		punpckhdq       %%mm4, %%mm4            /* 1.1 | 1.1 */
-		punpckldq       %%mm1, %%mm4            /* 1.2 | 1.1 */
+		"movq            %%mm0, %%mm4\n\t"
+		"punpckhdq       %%mm4, %%mm4\n\t"
+		"punpckldq       %%mm1, %%mm4\n\t"
 
-		movq            %%mm2, %%mm5            /* 2.1 | 2.0 */
-		punpckhdq       %%mm2, %%mm5            /* 2.1 | 2.1 */
-		punpckldq       %%mm3, %%mm5            /* 2.2 | 2.1 */
+		"movq            %%mm2, %%mm5\n\t"
+		"punpckhdq       %%mm2, %%mm5\n\t"
+		"punpckldq       %%mm3, %%mm5\n\t"
 
-		pfmul           %%mm2, %%mm4            /* 1.2 * 2.1 | 2.0 * 1.1 */
-		pfmul           %%mm0, %%mm5            /* 1.1 * 2.2 | 1.0 * 2.1 */
+		"pfmul           %%mm2, %%mm4\n\t"
+		"pfmul           %%mm0, %%mm5\n\t"
 
-		pfmul           %%mm0, %%mm3            /* - | 1.0 * 2.2 */
-		pfmul           %%mm2, %%mm1            /* - | 2.0 * 1.2 */
+		"pfmul           %%mm0, %%mm3\n\t"
+		"pfmul           %%mm2, %%mm1\n\t"
 
-		pfsub           %%mm4, %%mm5            /* 0 | 2 */
-		pfsub           %%mm3, %%mm1            /* - | 1 */
+		"pfsub           %%mm4, %%mm5\n\t"
+		"pfsub           %%mm3, %%mm1\n\t"
 
-		movq            %%mm5, %%mm6            /* 0 | 2 */
-		punpckldq       %%mm1, %%mm1            /* 1 | 1 */
-		punpckhdq       %%mm1, %%mm6            /* 1 | 0 */
+		"movq            %%mm5, %%mm6\n\t"
+		"punpckldq       %%mm1, %%mm1\n\t"
+		"punpckhdq       %%mm1, %%mm6\n\t"
 
-		movq            %%mm6, (%2)             /* 1 | 0 */
-		movq            %%mm5, 8(%2)            /* - | 2 */
+		"movq            %%mm6, (%2)\n\t"
+		"movq            %%mm5, 8(%2)\n\t"
 
-		femms
-		"
+		"femms\n\t"
 		:
 		: "a" (vec1), "b" (vec2), "d" (v)
 		);
@@ -233,24 +228,23 @@
 #ifdef USE_SSE
 	if (cpuid & FLAG_SSE) {
 		__asm__ (
-		"
-		movups  (%0), %%xmm0                    /* 1.0 | 1.1 | 1.2 | - */
-		movups  (%1), %%xmm1                    /* 2.0 | 2.1 | 2.2 | - */
+		
+		"movups  (%0), %%xmm0\n\t"
+		"movups  (%1), %%xmm1\n\t"
 
-		movups  %%xmm0, %%xmm2                  /* 1.0 | 1.1 | 1.2 | - */
-		shufps  $201, %%xmm2, %%xmm2            /* 1.1 | 1.2 | 1.0 | - */
-		movups  %%xmm1, %%xmm3                  /* 2.0 | 2.1 | 2.2 | - */
-		shufps  $201, %%xmm3, %%xmm3            /* 2.1 | 2.2 | 2.0 | - */
+		"movups  %%xmm0, %%xmm2\n\t"
+		"shufps  $201, %%xmm2, %%xmm2\n\t"
+		"movups  %%xmm1, %%xmm3\n\t"
+		"shufps  $201, %%xmm3, %%xmm3\n\t"
 
-		mulps   %%xmm1, %%xmm2                  /* 1.1 * 2.0 | 1.2 * 2.1 | 1.0 * 2.2 | - */
-		mulps   %%xmm0, %%xmm3                  /* 2.1 * 1.0 | 2.2 * 1.1 | 2.0 * 1.2 | - */
+		"mulps   %%xmm1, %%xmm2\n\t"
+		"mulps   %%xmm0, %%xmm3\n\t"
 
-		subps   %%xmm2, %%xmm3                  /* 2 | 0 | 1 | - */
+		"subps   %%xmm2, %%xmm3\n\t"
 
-		shufps  $201, %%xmm3, %%xmm3            /* 0 | 1 | 2 | - */
+		"shufps  $201, %%xmm3, %%xmm3\n\t"
 
-		movups  %%xmm3, (%2)                    /* 0 | 1 | 2 | - */
-		"
+		"movups  %%xmm3, (%2)\n\t"
 		: 
 		: "a" (vec1), "c" (vec2), "d" (v)
 		);
